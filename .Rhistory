Computer_data <- read.csv(file.choose())
View(Computer_data)
class(Computer_data)
#Exploratory data analysis
attach(Computer_data)
library(psych)
describe(Computer_data)
library(plyr)
Computer_data1 <- Computer_data
Computer_data1$cd <- as.numeric(revalue(Computer_data1$cd,c("yes"=1, "no"=0)))
Computer_data1$multi <- as.numeric(revalue(Computer_data1$multi,c("yes"=1, "no"=0)))
Computer_data1$premium <- as.numeric(revalue(Computer_data1$premium,c("yes"=1, "no"=0)))
View(Computer_data1)
class(Computer_data1)
attach(Computer_data1)
summary(Computer_data1)
pairs(Computer_data1)
cor(Computer_data1)
library(corpcor)
cor2pcor(cor(Computer_data1))
#The linear model of intrest with all variables
Model.Computer <- lm(price~speed+hd+ram+screen+cd+multi+premium+ads+trend)
summary(Model.Computer)  # Adjusted R2 Value - 0.7752
### Scatter plot matrix along with Correlation Coefficients
panel.cor<-function(x,y,digits=2,prefix="",cex.cor)
{
usr<- par("usr"); on.exit(par(usr))
par(usr=c(0,1,0,1))
r=(cor(x,y))
txt<- format(c(r,0.123456789),digits=digits)[1]
txt<- paste(prefix,txt,sep="")
if(missing(cex.cor)) cex<-0.4/strwidth(txt)
text(0.5,0.5,txt,cex=cex)
}
pairs(Computer_data1,upper.panel = panel.cor,main="Scatter plot matrix with Correlation coefficients")
library(mvinfluence)
library(car)
influence.measures(Model.Computer)
getOption("max.print")
setOption("max.print")
## plotting Influential measures
influenceIndexPlot(Model.Computer, id.n=3)# index plots for infuence measures
influencePlot(Model.Computer, id.n=3) # A user friendly representation of the above
Model.Computer1<-lm(price~speed+hd+ram+screen+cd+multi+premium+ads+trend,
data=Computer_data1[-c(1441,1701),])
summary(Model.Computer1)
# Logarthimic Transformation
Model.Computer_dataLog <- lm(price~log(speed)+log(hd)+log(ram)+log(screen)+
log(cd)+log(multi)+log(premium)+log(ads)+log(trend)
,data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_dataLog)      ## Adjusted R2 Value - 0.7441
# Exponential Transformation :
Model.Computer_exp<-lm(log(price)~speed+hd+ram+screen+cd+multi+premium+ads+trend,
data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_exp)  #Adjusted R2 Value is 0.7833
# Quad Model
Model.Computer_Quad <- lm(price~speed+I(speed^2)+hd+I(hd^2)+ram+I(ram^2)+screen+I(screen^2)+
+cd+I(cd^2)+multi+I(multi^2)+premium+I(premium^2)
+ads+I(ads^2)+trend+I(trend^2),data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_Quad)  #Adjusted R2 value is 0.8049
# Poly Modal
Model.Computer_Poly <- lm(price~speed+I(speed^2)+I(speed^3)+
hd+I(hd^2)+I(hd^3)+
ram+I(ram^2)+I(ram^3)+
screen+I(screen^2)+I(screen^3)+
cd+I(cd^2)+I(cd^3)+
multi+I(multi^2)+I(multi^3)+
premium+I(premium^2)+I(premium^3)+
ads+I(ads^2)+I(ads^3)+
trend+I(trend^2)+I(trend^3),data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_Poly) #Adjusted R Square Value is 0.813
finalmodel <- Model.Computer_Poly
summary(finalmodel)
predict(finalmodel,interval = "predict")
plot(finalmodel)
qqPlot((finalmodel),id.n=5)
vif(Model.Computer)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(Model.Computer,id.n=2,id.cex=0.7)
Cars <- read.csv(file.choose()) # choose the Cars.csv data set
View(Cars)
summary(Cars)
# 7. Find the correlation b/n Output (MPG) & (HP,VOL,SP)-Scatter plot
pairs(Cars)
# 8. Correlation Coefficient matrix - Strength & Direction of Correlation
cor(Cars)
### Partial Correlation matrix - Pure Correlation  b/n the varibles
#install.packages("corpcor")
library(corpcor)
cor2pcor(cor(Cars))
# The Linear Model of interest with all the columns
model.car <- lm(MPG~.,data=Cars)
summary(model.car)
# Multicollinearity check
# Model based on only Volume
model.carV<-lm(MPG~VOL,data=Cars)
summary(model.carV) # Volume became significant
# Model based on only Weight
model.carW<-lm(MPG~WT,data=Cars)
summary(model.carW) # Weight became significant
# Model based on Volume and Weight
model.carVW<-lm(MPG~VOL+WT,data=Cars)
summary(model.carVW) # Both became Insignificant
# Applying VIF function on model built on all inputs
## Variance Inflation factor to check collinearity b/n variables
vif(model.car) # Original model
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(model.car,id.n=2,id.cex=0.7)
### Scatter plot matrix along with Correlation Coefficients
panel.cor<-function(x,y,digits=2,prefix="",cex.cor)
{
usr<- par("usr"); on.exit(par(usr))
par(usr=c(0,1,0,1))
r=(cor(x,y))
txt<- format(c(r,0.123456789),digits=digits)[1]
txt<- paste(prefix,txt,sep="")
if(missing(cex.cor)) cex<-0.4/strwidth(txt)
text(0.5,0.5,txt,cex=cex)
}
pairs(Cars,upper.panel = panel.cor,main="Scatter plot matrix with Correlation coefficients")
# It is Better to delete influential observations rather than deleting entire column which is
# costliest process
# Deletion Diagnostics for identifying influential observations
influence.measures(model.car)
library(car)
## plotting Influential measures
windows()
influenceIndexPlot(model.car,id.n=3) # index plots for infuence measures
influencePlot(model.car,id.n=3) # A user friendly representation of the above
# Regression after deleting the 77th observation, which is influential observation
model_1<-lm(MPG~.-WT,data=Cars[-77,])
summary(model_1)
# Regression after deleting the 77th & 71st Observations
model_2<-lm(MPG~.-WT,data=Cars[-c(71,77),])
summary(model_2)
## Final model
plot(lm(MPG~.-WT,data=Cars[-c(77),])) # 77
summary(lm(MPG~.-WT,data=Cars[-c(77,79,80),]))
finalmodel<-lm(MPG~.-WT,data=Cars[-c(77,79),])
summary(finalmodel)
# Evaluate model LINE assumptions
plot(finalmodel)
## Apply different transformations on input check if they
### TASK #######
## Apply different transformations on input check if they
# are they giving better Adjusted R_Squared and
### TASK #######
## Apply different transformations on input check if they
# are they giving better Adjusted R_Squared and
# less RMSE also check different plots which we used them
## Apply Ridge and Lasso Regression on this data
## Apply Ridge and Lasso Regression on this data
# and check whether it is giving better Adjst.R_sqrd
## Apply Ridge and Lasso Regression on this data
# and check whether it is giving better Adjst.R_sqrd
# and less rmse values are not
## Apply Ridge and Lasso Regression on this data
# and check whether it is giving better Adjst.R_sqrd
# and less rmse values are not
## Apply Ridge and Lasso Regression on this data
# and check whether it is giving better Adjst.R_sqrd
# and less rmse values are not
startups <- read.csv(file.choose())
View(startups)
library(plyr)
startups$State <- revalue(startups$State,
c("New York"="0", "California"="1", "Florida"="2"))
attach(startups)
Startups <- cbind(RD_Spend=R.D.Spend,Administration,Marketing_Spend=Marketing.Spend,State,Profit)
Startups1 <- as.data.frame(Startups)
attach(Startups1)
summary(Startups1)
pairs(Startups1)
cor(Startups1)
library(corpcor)
cor2pcor(cor(Startups1))
# The Linear Model of interest with all the columns
Model.Startups <- lm(Profit~RD_Spend+Administration+Marketing_Spend+State)
summary(Model.Startups)
### Scatter plot matrix along with Correlation Coefficients
panel.cor<-function(x,y,digits=2,prefix="",cex.cor)
{
usr<- par("usr"); on.exit(par(usr))
par(usr=c(0,1,0,1))
r=(cor(x,y))
txt<- format(c(r,0.123456789),digits=digits)[1]
txt<- paste(prefix,txt,sep="")
if(missing(cex.cor)) cex<-0.4/strwidth(txt)
text(0.5,0.5,txt,cex=cex)
}
pairs(Startups1,upper.panel = panel.cor,main="Scatter plot matrix with Correlation coefficients")
library(mvinfluence)
library(car)
# It is Better to delete influential observations rather than deleting entire column which is
# costliest process
# Deletion Diagnostics for identifying influential observations
influence.measures(Model.Startups)
## plotting Influential measures
influenceIndexPlot(Model.Startups, id.n=3)# index plots for infuence measures
influencePlot(Model.Startups, id.n=3) # A user friendly representation of the above
vif(Model.Startups)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(Model.Startups,id.n=2,id.cex=0.7)
# It is Better to delete influential observations rather than deleting entire column which is
# costliest process
# Deletion Diagnostics for identifying influential observations
influence.measures(Model.Startups)
## plotting Influential measures
influenceIndexPlot(Model.Startups, id.n=3)# index plots for infuence measures
influencePlot(Model.Startups, id.n=3) # A user friendly representation of the above
# Regression after deleting the 49th and 50th observation, which is influential observation
Model.Startups_Fin1<-lm(Profit~RD_Spend+Administration+Marketing_Spend+State,data=Startups1[-c(49,50),])
summary(Model.Startups_Fin1) #adjusted r-squared value = 0.9593
Model.Startups_Log<-lm(Profit~RD_Spend+log(Administration)+Marketing_Spend+log(State),data=Startups1[-c(49,50),])
summary(Model.Startups_Log) #Adjusted R2 Value = 0.9591
confint(Model.Startups_Log,level=0.95)
predict(Model.Startups_Log,interval="predict")
# Exponential Transformation :
Model.Startups_exp<-lm(log(Profit)~RD_Spend+Administration+Marketing_Spend+State,data=Startups1[-c(49,50),])
summary(Model.Startups_exp)  #Adjusted R2 Value is 0.9182
# Quad Model
Model.Startups_Quad <- lm(Profit~RD_Spend+I(RD_Spend^2)+Administration+I(Administration^2)
+Marketing_Spend+I(Marketing_Spend^2)+State+I(State^2),data=Startups1[-c(49,50),])
summary(Model.Startups_Quad)  #Adjusted R2 value is 0.9567
### Variance Inflation Factors is a formal way to check for collinearity
vif(Model.Startups_Log)  # VIF is > 10 => collinearity
avPlots(Model.Startups_Log, id.n=2, id.cex=0.7)# Added Variable Plots
# Final Model
FinalModel<-Model.Startups_Log
summary(FinalModel) #Adjusted R2 Value = 0.9591
predict(FinalModel,interval="predict")
plot(FinalModel)
rsquared_value <- as.table(rsquared_value)
rsquared_value
#R-squared value table
rsquared_value <-  matrix(c(0.9464,0.9593,0.9591,0.9182,0.9567,0.9591),ncol=1,byrow =TRUE)
colnames(rsquared_value) <- c("R-squared values")
rownames(rsquared_value) <- c("original model","model without influential values","log model","exponential model","quad model","Final model")
rsquared_value <- as.table(rsquared_value)
rsquared_value
vif(Model.Computer)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(Model.Computer,id.n=2,id.cex=0.7)
influence.measures(Model.Computer)
## plotting Influential measures
influenceIndexPlot(Model.Computer, id.n=3)# index plots for infuence measures
influencePlot(Model.Computer, id.n=3) # A user friendly representation of the above
#Regression model after deleting the 1441th and 1701th observation which are influential observations.
Model.Computer1<-lm(price~speed+hd+ram+screen+cd+multi+premium+ads+trend,
data=Computer_data1[-c(1441,1701),])
summary(Model.Computer1) #R-squared value = 0.7774
# Logarthimic Transformation
Model.Computer_dataLog <- lm(price~log(speed)+log(hd)+log(ram)+log(screen)+
log(cd)+log(multi)+log(premium)+log(ads)+log(trend)
,data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_dataLog)      ## Adjusted R2 Value - 0.7441
# Exponential Transformation :
Model.Computer_exp<-lm(log(price)~speed+hd+ram+screen+cd+multi+premium+ads+trend,
data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_exp)  #Adjusted R2 Value is 0.7833
# Quad Model
Model.Computer_Quad <- lm(price~speed+I(speed^2)+hd+I(hd^2)+ram+I(ram^2)+screen+I(screen^2)+
+cd+I(cd^2)+multi+I(multi^2)+premium+I(premium^2)
+ads+I(ads^2)+trend+I(trend^2),data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_Quad)  #Adjusted R2 value is 0.8049
# Poly Model
Model.Computer_Poly <- lm(price~speed+I(speed^2)+I(speed^3)+
hd+I(hd^2)+I(hd^3)+
ram+I(ram^2)+I(ram^3)+
screen+I(screen^2)+I(screen^3)+
cd+I(cd^2)+I(cd^3)+
multi+I(multi^2)+I(multi^3)+
premium+I(premium^2)+I(premium^3)+
ads+I(ads^2)+I(ads^3)+
trend+I(trend^2)+I(trend^3),data=Computer_data1[-c(1441,1701),])
summary(Model.Computer_Poly) #Adjusted R Square Value is 0.813
finalmodel <- Model.Computer_Poly
summary(finalmodel)
predict(finalmodel,interval = "predict")
plot(finalmodel)
qqPlot((finalmodel),id.n=5) #Normal QQ-plot helps in identifying outliers
Bank_Data <- read.csv(file.choose()) # Choose the claimants Data set
View(Bank_Data)
Bank_Data <- read.csv(file.choose()) # Choose the claimants Data set
View(Bank_Data)
Bank_Data <- read.csv(file.choose()) # Choose the claimants Data set
View(Bank_Data)
attach(Bank_Data)
colnames(Bank_Data)
Bank_Data <- read.csv(file.choose()) # Choose the claimants Data set
attach(Bank_Data)
colnames(Bank_Data)
Bank_Data <- read.csv(file.choose())
attach(Bank_Data)
colnames(Bank_Data)
class(Bank_Data)
mod_lm <- lm(HasFD~.,data=Bank_Data)
mod_lm <- lm(age.job.marital.education.default.balance.housing.loan.contact.day.month.duration.campaign.pdays.previous.poutcome.y~.,data=Bank_Data)
Bank_Data <- read.csv("C://Users//LENOVO//Desktop//ExcelR//Data Science Assignments//Logistic Regression//bank-full.csv",sep = ';')
attach(Bank_Data)
colnames(Bank_Data)
View(Bank_Data)
View(Bank_Data)
claimants <- read.csv(file.choose()) # Choose the claimants Data set
View(claimants)
sum(is.na(claimants))
claimants <- na.omit(claimants) # Omitting NA values from the Data
# na.omit => will omit the rows which has atleast 1 NA value
dim(claimants)
colnames(claimants)
claimants <- claimants[,-1] # Removing the first column which is is an Index
# Preparing a linear regression
mod_lm <- lm(ATTORNEY~.,data=claimants)
pred1 <- predict(mod_lm,claimants)
pred1
plot(claimants$CLMINSUR,pred1)
# We can no way use the linear regression technique to classify the data
plot(pred1)
# GLM function use sigmoid curve to produce desirable results
# The output of sigmoid function lies in between 0-1
model <- glm(ATTORNEY~.,data=claimants,family = "binomial")
# To calculate the odds ratio manually we going r going to take exp of coef(model)
exp(coef(model))
# Confusion matrix table
prob <- predict(model,claimants,type="response")
summary(model)
# Confusion matrix and considering the threshold value as 0.5
confusion<-table(prob>0.5,claimants$ATTORNEY)
confusion
# Model Accuracy
Accuracy<-sum(diag(confusion)/sum(confusion))
Accuracy # 70.62
# Creating empty vectors to store predicted classes based on threshold value
pred_values <- NULL
yes_no <- NULL
pred_values <- ifelse(prob>=0.5,1,0)
yes_no <- ifelse(prob>=0.5,"yes","no")
# Creating new column to store the above values
claimants[,"prob"] <- prob
claimants[,"pred_values"] <- pred_values
claimants[,"yes_no"] <- yes_no
View(claimants[,c(1,7:9)])
table(claimants$ATTORNEY,claimants$pred_values)
# ROC Curve => used to evaluate the betterness of the logistic model
# more area under ROC curve better is the model
# We will use ROC curve for any classification technique not only for logistic
library(ROCR)
rocrpred<-prediction(prob,claimants$ATTORNEY)
rocrperf<-performance(rocrpred,'tpr','fpr')
str(rocrperf)
plot(rocrperf,colorize=T,text.adj=c(-0.2,1.7))
## Getting cutt off or threshold value along with true positive and false positive rates in a data frame
str(rocrperf)
rocr_cutoff <- data.frame(cut_off = rocrperf@alpha.values[[1]],fpr=rocrperf@x.values,tpr=rocrperf@y.values)
colnames(rocr_cutoff) <- c("cut_off","FPR","TPR")
View(rocr_cutoff)
library(dplyr)
rocr_cutoff$cut_off <- round(rocr_cutoff$cut_off,6)
# Sorting data frame with respect to tpr in decreasing order
rocr_cutoff <- arrange(rocr_cutoff,desc(TPR))
View(rocr_cutoff)
Corolla <- read.csv(file.choose())
View(Corolla)
attach(Corolla)
Corolla_Pred <- cbind(Price,Age_08_04,KM,HP,cc,Doors,Gears,Quarterly_Tax,Weight)
Corolla_Pred1 <- as.data.frame(Corolla_Pred)
class(Corolla_Pred1)
View(Corolla_Pred1)
attach(Corolla_Pred1)
library(psych)
describe(Corolla_Pred1)
summary(Corolla_Pred1)
pairs(Corolla_Pred1)
cor(Corolla_Pred1)
library(corpcor)
cor2pcor(cor(Corolla_Pred1))
#The linear model with all variables
corolla.price <- lm(Price~Age_08_04+KM+HP+cc+Doors+Gears+Quarterly_Tax+Weight)
summary(corolla.price)
corolla.price2 <-lm(Price~Age_08_04+KM+HP+Gears+Quarterly_Tax+Weight)
summary(corolla.price2)
### Scatter plot matrix with Correlations inserted in graph
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r = (cor(x, y))
txt <- format(c(r, 0.123456789), digits=digits)[1]
txt <- paste(prefix, txt, sep="")
if(missing(cex.cor)) cex <- 0.4/strwidth(txt)
text(0.5, 0.5, txt, cex = cex)
}
pairs(Corolla_Pred1, upper.panel=panel.cor,main="Scatter Plot Matrix with Correlation Coefficients")
library(mvinfluence)
library(car)
# Applying VIF function on model built on all inputs
## Variance Inflation factor to check collinearity b/n variables
vif(corolla.price)
## vif>10 then there exists collinearity among all the variables
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(corolla.price,id.n=2,id.cex=0.7)
influence.measures(corolla.price)
## plotting Influential measures
influenceIndexPlot(corolla.price, id.n=3)# index plots for infuence measures
influencePlot(corolla.price, id.n=3) # A user friendly representation of the above
## Regression after deleting the 81st observation, which is influential observation
corolla.price1 <- lm(Price~Age_08_04+KM+HP+cc+Doors+Gears+Quarterly_Tax+Weight,data=Corolla_Pred1[-81,])
summary(corolla.price1)
finalmodel <- corolla.price
summary(finalmodel)
predict(finalmodel,interval="predict")
pred_final <- predict(corolla.price)
Final <- cbind(Price,pred_final,Age_08_04,KM,HP,cc,Doors,Gears,Quarterly_Tax,Weight)
View(Final)
plot(finalmodel)
qqPlot(finalmodel, id.n=5) # QQ plots helps identify outliers
Computer_data <- read.csv(file.choose())
Corolla <- read.csv(file.choose())
View(Corolla)
